{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8651f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba8930e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Life Science', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'published_in': 'Significance, 2021', 'year': 2021, 'url': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'doi': '1740-9713.01589'}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
      "           name     role         type demographic  \\\n",
      "0  sepal length  Feature   Continuous        None   \n",
      "1   sepal width  Feature   Continuous        None   \n",
      "2  petal length  Feature   Continuous        None   \n",
      "3   petal width  Feature   Continuous        None   \n",
      "4         class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                               None    cm             no  \n",
      "1                                               None    cm             no  \n",
      "2                                               None    cm             no  \n",
      "3                                               None    cm             no  \n",
      "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
     ]
    }
   ],
   "source": [
    "#uploading the iris data directly from the UCI machine learning repository\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "data = iris.data.features \n",
    "target = iris.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(iris.metadata)\n",
    "\n",
    "# variable information \n",
    "print(iris.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "67458823",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data \n",
    "\n",
    "#clusters\n",
    "k = 3\n",
    "\n",
    "#points per cluster = n/k\n",
    "cluster_len = len(X) // k\n",
    "\n",
    "#storing the mean for each cluster in a list\n",
    "initial_means = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb5a86a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected maximization\n",
    "for i in range(k):\n",
    "    s_i = i * cluster_len\n",
    "    e_i = (i + 1) * cluster_len\n",
    "    cluster_data = X[s_i:e_i]\n",
    "    #calculating the new mean and appending it\n",
    "    mean = np.mean(cluster_data, axis=0)\n",
    "    initial_means.append(mean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6652d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guassian mixture calculation \n",
    "gmm = GaussianMixture(n_components=n_clusters, means_init=np.array(initial_means),\n",
    "                      covariance_type='full')\n",
    "\n",
    "# intializing the maximum number of iterations,convergence tolerance\n",
    "max_iterations = 50\n",
    "tolerance = 0.000001  \n",
    "converged = False\n",
    "\n",
    "#checking for convergence\n",
    "for i in range(max_iterations):\n",
    "    gmm.fit(X)\n",
    "    if i > 0:\n",
    "        mean_distances = [euclidean(old_mean, new_mean) for old_mean, new_mean in zip(old_means, gmm.means_)]\n",
    "        if all(distance < tolerance for distance in mean_distances):\n",
    "            converged = True\n",
    "            break\n",
    "    old_means = gmm.means_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "084e2fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 3 iterations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if converged:\n",
    "    print(f\"Converged after {i+1} iterations.\\n\")\n",
    "else:\n",
    "    print(\"Did not converge within the maximum number of iterations.\\n\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a43469c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 1 (Norm: 6.240640):\n",
      "[5.006 3.418 1.464 0.244]\n",
      "\n",
      "Mean 2 (Norm: 7.871425):\n",
      "[5.91173838 2.77894708 4.19651417 1.29514342]\n",
      "\n",
      "Mean 3 (Norm: 9.236381):\n",
      "[6.54088231 2.9460898  5.47090074 1.97924237]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_means = sorted(zip(initial_means, gmm.means_), key=lambda x: np.linalg.norm(x[0]))\n",
    "\n",
    "for i, (initial_mean, final_mean) in enumerate(sorted_means):\n",
    "    print(f\"Mean {i+1} (Norm: {np.linalg.norm(final_mean):.6f}):\\n{final_mean}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5bb34f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix for Mean 1:\n",
      "[[0.38656354 0.09273542 0.3043059  0.0634571 ]\n",
      " [0.09273542 0.11084912 0.08645572 0.05724244]\n",
      " [0.3043059  0.08645572 0.33350613 0.07892995]\n",
      " [0.0634571  0.05724244 0.07892995 0.08814876]]\n",
      "\n",
      "Covariance Matrix for Mean 2:\n",
      "[[0.38656354 0.09273542 0.3043059  0.0634571 ]\n",
      " [0.09273542 0.11084912 0.08645572 0.05724244]\n",
      " [0.3043059  0.08645572 0.33350613 0.07892995]\n",
      " [0.0634571  0.05724244 0.07892995 0.08814876]]\n",
      "\n",
      "Covariance Matrix for Mean 3:\n",
      "[[0.38656354 0.09273542 0.3043059  0.0634571 ]\n",
      " [0.09273542 0.11084912 0.08645572 0.05724244]\n",
      " [0.3043059  0.08645572 0.33350613 0.07892995]\n",
      " [0.0634571  0.05724244 0.07892995 0.08814876]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#covariance matrix of each cluster \n",
    "for i, (initial_mean, final_mean) in enumerate(sorted_means):\n",
    "    covariance_matrix = gmm.covariances_[mean_index]\n",
    "    print(f\"Covariance Matrix for Mean {i+1}:\\n{covariance_matrix}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "21b2ac10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49\n",
      "Cluster 2: 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 73, 74, 75, 76, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99\n",
      "Cluster 3: 68, 70, 72, 77, 83, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149\n",
      "Size: 50 45 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13179\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but GaussianMixture was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#cluster assignments for each data point\n",
    "cluster_assignments = gmm.predict(X)\n",
    "\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    members = np.where(cluster_assignments == i)[0]  \n",
    "    sorted_members = np.sort(members)  \n",
    "    print(f\"Cluster {i+1}: {', '.join(map(str, sorted_members))}\")\n",
    "\n",
    "# final size of each cluster\n",
    "cluster_sizes = [np.sum(cluster_assignments == i) for i in range(n_clusters)]\n",
    "print(\"Size:\", ' '.join(map(str, cluster_sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c87cfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd4511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b54f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y_true = target  # True labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "82018be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.966667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13179\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but GaussianMixture was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y_true = iris.target  # True labels\n",
    "\n",
    "# Define the number of clusters (k)\n",
    "n_clusters = 3\n",
    "\n",
    "\n",
    "# Compute cluster assignments for each data point\n",
    "cluster_assignments = gmm.predict(X)\n",
    "\n",
    "# Compute confusion matrix to determine purity\n",
    "conf_matrix = confusion_matrix(y_true, cluster_assignments)\n",
    "\n",
    "# Calculate purity\n",
    "purity = np.sum(np.amax(conf_matrix, axis=0)) / len(X)\n",
    "\n",
    "# Display purity score\n",
    "print(f\"Purity: {purity:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad6041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
